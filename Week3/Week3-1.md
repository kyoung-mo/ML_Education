
# π“ Week3β€‘1 β€“ μΈκ³µμ‹ κ²½λ§ κµ¬μ΅° & νλΌλ―Έν„°
---

## π§  μΈκ³µμ‹ κ²½λ§(Artificial Neural Network, **ANN**)

### 1οΈβƒ£ κ°λ…
- **μΈκ³µλ‰΄λ°(Perceptron)** μλ°±~μλ§ κ°λ¥Ό **κ³„μΈµ(layer)** μΌλ΅ μ—°κ²°ν• ν•¨μ κ·Όμ‚¬ λ¨λΈ  
- μ…λ ¥ β†’ κ°€μ¤‘ν•© β†’ λΉ„μ„ ν• λ³€ν™ β†’ μ¶λ ¥ κ³Όμ •μ„ **μ „ν(Propagation)** ν•λ©°,  
  **μ¤μ°¨(μ†μ‹¤)** λ¥Ό μ—­μΌλ΅ μ „ν(Backβ€‘propagation)ν•΄ νλΌλ―Έν„°λ¥Ό ν•™μµ  
- μ΄λ΅ μ μΌλ΅ μ€λ‹‰μΈµμ΄ μ¶©λ¶„ν•λ©΄ **λ¨λ“  μ—°μ†ν•¨μ**λ¥Ό κ·Όμ‚¬ν•  μ μμ(Universal Approximation).

<img src="https://raw.githubusercontent.com/ml-assets/ann-drawing/main/ann_layers.svg" width="480"/>

---

### 2οΈβƒ£ λ‰΄λ°(Neuron)μ μμ‹
\[
y = f(\underbrace{\sum_{i=1}^{n}w_i x_i}_{\text{κ°€μ¤‘ν•©}} + \; b)
\]

| κΈ°νΈ | μλ―Έ | ν•™μµ λ€μƒ? |
|------|------|-----------|
| \(x_i\) | μ…λ ¥ Feature | β |
| \(w_i\) | κ°€μ¤‘μΉ(Weight) | β… |
| \(b\) | νΈν–¥(Bias) | β… |
| \(f(\cdot)\) | **ν™μ„±ν™” ν•¨μ** | β (μ„ νƒ μ‚¬ν•­) |

> **λ²΅ν„°ν™”**  
> \(\boldsymbol{y}=f(\mathbf{W}\mathbf{x}+\mathbf{b})\) λ΅ ν‘ν„ν•λ©°, λΌμ΄λΈλ¬λ¦¬μ—μ„λ” ν–‰λ ¬κ³±(\*) ν• μ¤„λ΅ κµ¬ν„ν•©λ‹λ‹¤.

---

## β™οΈ ν™μ„±ν™” ν•¨μ ν•λμ—

| ν•¨μ | μ‹ | νΉμ§• |
|------|----|------|
| **Sigmoid** | \( \sigma(z)=\frac1{1+e^{-z}} \) | ν™•λ¥  ν•΄μ„ μ©μ΄, **vanishing gradient** |
| **Tanh** | \( \tanh(z) \) | 0 μ¤‘μ‹¬μ΄μ§€λ§ μ—¬μ „ν vanishing |
| **ReLU** | \( \max(0,z) \) | κ³„μ‚° λ‹¨μ, λΉ λ¥Έ μλ ΄, dying ReLU μ£Όμ |
| **Leaky ReLU** | \( \max(\alpha z, z) \) | ReLUμ μμ μμ—­ κΈ°μΈκΈ° λ³΄μ™„ |
| **Softmax** | \( \frac{e^{z_k}}{\sum_j e^{z_j}} \) | λ‹¤μ¤‘ ν΄λμ¤ ν™•λ¥  λ¶„ν¬ |

---

## π”© νλΌλ―Έν„°(Parameter)

### 1οΈβƒ£ μΆ…λ¥
| νλΌλ―Έν„° | κ³„μΈµλ‹Ή κ°μ | μ—­ν•  |
|----------|------------|------|
| **Weights** | μ…λ ¥λ…Έλ“ Γ— μ¶λ ¥λ…Έλ“ | λ°μ΄ν„° κ°„ μ¤‘μ”λ„ ν•™μµ |
| **Biases** | μ¶λ ¥λ…Έλ“ | κ²°μ •κ²½κ³„ μ΄λ™Β·μ¶λ ¥ λ³΄μ • |

### 2οΈβƒ£ νλΌλ―Έν„° μ κ³„μ‚° μ
> **κµ¬μ΅°**: Input 4 β†’ HiddenΒ 8 β†’ OutputΒ 3  
> \[
\#W = 4 \times 8 + 8 \times 3 = 44, \quad
\#b = 8 + 3 = 11, \quad
\textbf{μ΄}\;55\;\text{κ°}
\]

---

## π”§ PyTorch μ‹¤μµ μμ 

```python
import torch
import torch.nn as nn

class SimpleNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(4, 8),   # μ…λ ¥ 4, μ€λ‹‰ 8
            nn.ReLU(),
            nn.Linear(8, 3)    # μ€λ‹‰ 8, μ¶λ ¥ 3
        )

    def forward(self, x):
        return self.net(x)
```

### νλΌλ―Έν„° ν™•μΈ
```python
model = SimpleNN()
print(model)

total = sum(p.numel() for p in model.parameters())
print("μ΄ νλΌλ―Έν„°:", total)  # 55κ°
```

### λ―Έλ‹ ν•™μµ λ£¨ν”„ μμ‹
```python
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()

for epoch in range(epochs):
    optimizer.zero_grad()
    logits = model(x_train)          # μμ „ν
    loss = criterion(logits, y_train)
    loss.backward()                  # μ—­μ „ν
    optimizer.step()                 # νλΌλ―Έν„° κ°±μ‹ 
```

---

## π§‘β€π« ANN ν•™μµ ν”„λ΅μ„Έμ¤ μ”μ•½
1. **μμ „ν(Forward Pass)**: μ…λ ¥μ„ ν†µν•΄ μ¶λ ¥ κ³„μ‚° β†’ μ†μ‹¤ \(\mathcal{L}\) μ‚°μ¶  
2. **μ—­μ „ν(Backward Pass)**: \(\frac{\partial \mathcal{L}}{\partial w},\frac{\partial \mathcal{L}}{\partial b}\) κ³„μ‚°  
3. **μµν‹°λ§μ΄μ €(Optimizer)**: SGβ€‹D, Adam λ“±μΌλ΅ νλΌλ―Έν„° μ—…λ°μ΄νΈ  
4. **λ°λ³µ(Epoch)**: λ°μ΄ν„°μ…‹μ„ ν• λ°”ν€΄ μν β†’ μ†μ‹¤Β·μ •ν™•λ„ λ¨λ‹ν„°λ§  
5. **μΌλ°ν™”(Generalization)**: κ²€μ¦/ν…μ¤νΈ λ°μ΄ν„°λ΅ κ³Όμ ν•© μ—¬λ¶€ ν™•μΈ

---

## π― κ³Όμ 

> **μ΅°κ±΄**: PyTorch μ‚¬μ©, Colab μ¶”μ²

1. **λ¨λΈ μ„¤κ³„** β€“ μ…λ ¥ 2, μ€λ‹‰μΈµ 4(1κ° μΈµ), μ¶λ ¥ 1μΈ μ‹ κ²½λ§μ„ κµ¬μ¶•ν•μ„Έμ”.  
2. **νλΌλ―Έν„° μ μ‚°μ¶** β€“ μ§μ ‘ κ³„μ‚°ν• κ°’κ³Ό `sum(p.numel()Β forΒ pΒ inΒ model.parameters())` κ²°κ³Όλ¥Ό λΉ„κµν•΄ λ³΄μ„Έμ”.  
3. **`nn.Sequential` κµ¬ν„** β€“ κ³Όμ Β 1κ³Ό λ™μΌν• κµ¬μ΅°λ¥Ό `nn.Sequential` λ΅ μ¬κµ¬ν„ν•΄ λ³΄μ„Έμ”.

### ννΈ
```python
seq_model = nn.Sequential(
    nn.Linear(2, 4),
    nn.Tanh(),
    nn.Linear(4, 1)
)
print(seq_model)
print("νλΌλ―Έν„°:", sum(p.numel() for p in seq_model.parameters()))
```

> **μ¶”κ°€ λ„μ „ π**Β   
> β€Ά `torchinfo.summary(seq_model, input_size=(1,2))`λ΅ μƒμ„Έ κµ¬μ΅°λ¥Ό μ¶λ ¥ν•΄ λ³΄μ„Έμ”(ν¨ν‚¤μ§€ μ„¤μΉ ν•„μ”).  
> β€Ά κ°™μ€ λ¬Έμ λ¥Ό Keras/TensorFlowλ΅λ„ κµ¬ν„ν•΄ λΉ„κµν•΄ λ³΄μ„Έμ”.

---

β… **μ‚¬μ© ν™κ²½**: PythonΒ 3.x, GoogleΒ Colab, *PyTorchΒ β‰¥2.0*  
`!pip install torch torchvision torchinfo -q` λ΅ μ„¤μΉ ν›„ μ‹¤ν–‰ν•λ©΄ λ©λ‹λ‹¤.
