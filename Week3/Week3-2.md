# π“ Week3-2 - μ†μ‹¤ν•¨μ, μ—­μ „ν

---

## π“‰ μ†μ‹¤ ν•¨μ (Loss Function)

### π”Ή κ°λ…
- λ¨λΈμ μμΈ΅κ°’κ³Ό μ‹¤μ κ°’μ μ°¨μ΄λ¥Ό μμΉλ΅ ν‘ν„ν• κ²ƒ
- μ†μ‹¤(loss)μ„ μµμ†ν™”ν•λ” λ°©ν–¥μΌλ΅ λ¨λΈμ΄ ν•™μµλ¨

### π”Ή μ£Όμ” μ†μ‹¤ ν•¨μ
| ν•¨μλ… | μ„¤λ… | μ‚¬μ© μ |
|--------|------|--------|
| `MSELoss` | ν‰κ·  μ κ³± μ¤μ°¨ | νκ·€ λ¬Έμ  |
| `CrossEntropyLoss` | λ‹¤μ¤‘ ν΄λμ¤ λ¶„λ¥ | λ¶„λ¥ λ¬Έμ  |

### μμ‹
```python
import torch
import torch.nn as nn

# μμΈ΅κ°’κ³Ό μ‹¤μ κ°’
pred = torch.tensor([0.8, 0.1, 0.1])
target = torch.tensor([0])

# μ†μ‹¤ ν•¨μ μ •μ
loss_fn = nn.CrossEntropyLoss()
loss = loss_fn(pred.unsqueeze(0), target)
print(loss.item())
```

---

## π” μ—­μ „ν (Backpropagation)

### π”Ή κ°λ…
- μ†μ‹¤ ν•¨μμ κ°’μ΄ μ¤„μ–΄λ“¤λ„λ΅ νλΌλ―Έν„°(κ°€μ¤‘μΉ, νΈν–¥)λ¥Ό μ—…λ°μ΄νΈν•λ” μ•κ³ λ¦¬μ¦
- μ²΄μΈ λ£°(Chain Rule)μ„ ν†µν•΄ κ° νλΌλ―Έν„°μ— λ€ν• λ―Έλ¶„κ°’ κ³„μ‚°

### π”Ή PyTorchμ—μ„μ μ—­μ „ν νλ¦„
```python
loss.backward()      # μ†μ‹¤μ— λ€ν• μ—­μ „ν μν–‰
optimizer.step()     # νλΌλ―Έν„° μ—…λ°μ΄νΈ
optimizer.zero_grad()  # κΈ°μΈκΈ° μ΄κΈ°ν™”
```

---

## π§ μ‹¤μµ μμ‹: κ°„λ‹¨ν• ν•™μµ
```python
import torch
import torch.nn as nn
import torch.optim as optim

model = nn.Linear(1, 1)
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

x = torch.tensor([[1.0], [2.0], [3.0]])
y = torch.tensor([[2.0], [4.0], [6.0]])

for epoch in range(100):
    pred = model(x)
    loss = criterion(pred, y)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

print(model.weight.item(), model.bias.item())
```

---

## π§ κ³Όμ 
1. `nn.Linear(1,1)`μ„ μ‚¬μ©ν•μ—¬ y=3xμ— κ·Όμ‚¬ν•λ” λ¨λΈμ„ ν•™μµν•μ‹μ¤.
2. μ†μ‹¤ ν•¨μλ΅ `nn.MSELoss()`λ¥Ό μ‚¬μ©ν•κ³ , μ—ν­λ§λ‹¤ μ†μ‹¤ κ°’μ„ μ¶λ ¥ν•μ‹μ¤.
3. ν•™μµμ΄ λλ‚ ν›„ weightμ™€ bias κ°’μ„ μ¶λ ¥ν•μ‹μ¤.

---

β… μ‚¬μ© ν™κ²½: Python 3.x, Google Colab, PyTorch μ„¤μΉ ν•„μ”
